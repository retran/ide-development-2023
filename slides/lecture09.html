<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
	<title>IDE Development Course - Dynamic Analysis</title>
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.5.0/reset.min.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.5.0/reveal.min.css">
	<link rel="stylesheet" href="dist/theme/jetbrains-dark.css">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlightjs-themes@1.0.0/darkula.css">
</head>

<body>
	<div class="reveal">
		<div class="slides">

			<section class="background">
				<h1>Dynamic Analysis</h1>
				<p class="event-name-label">
					IDE Development Course
				</p>
				<p class="name-and-position-label">
					Andrew Vasilyev
				</p>
				<div class="jb-square-logo"></div>
				<p class="license-label">Licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a></p>
			</section>

			<section>
				<h3>Today's Agenda</h3>
				<ul>
					<li>Dynamic Analysis</li>
					<li>Performance Profiling</li>
					<li>Memory Profiling</li>
					<li>Test Coverage</li>
				</ul>
			</section>

			<section>
				<h2>Dynamic Analysis</h2>
			</section>

			<section>
				<h3>What is Dynamic Analysis?</h3>
				<ul>
					<li><b>Dynamic analysis</b> is the examination of a programâ€™s behavior <b>during execution</b>.</li>
					<li>Key for understanding runtime behavior, performance issues, and bugs.</li>
					<li>It allows for real-time error detection, performance optimization, and ensuring correctness of
						code.</li>
				</ul>
			</section>

			<section>
				<h3>Static vs Dynamic Analysis</h3>
				<table>
					<thead>
						<tr>
							<th>Aspect</th>
							<th>Static Analysis</th>
							<th>Dynamic Analysis</th>
						</tr>
					</thead>
					<tbody>
						<tr>
							<td>When it's performed</td>
							<td>Before program execution</td>
							<td>During program execution</td>
						</tr>
						<tr>
							<td>Error Detection</td>
							<td>Can detect potential issues early in the development cycle</td>
							<td>Identifies actual issues in real-time as the code executes</td>
						</tr>
						<tr>
							<td>Performance Analysis</td>
							<td>Limited to theoretical assessments</td>
							<td>Provides actual performance data</td>
						</tr>
					</tbody>
				</table>
			</section>

			<section>
				<h3>Dynamic Analysis Methods</h3>
				<ul>
					<li>Sampling: Periodic collection of data at set intervals to analyze program behavior.</li>
					<li>Instrumentation: Inserting additional code into the program to collect data during execution.
					</li>
					<li>Tracing: Recording events or function calls during program execution for later analysis.</li>
					<li>Hooks: Points in code where additional functionality can be inserted to gather data or alter
						program behavior.</li>
				</ul>
			</section>

			<section>
				<h3>Dynamic Analysis Methods</h3>
				<ul>
					<li>Hardware Performance Counters: Measure events like cache misses, branch mispredictions, etc.
					</li>
					<li>Instruction Set Simulator (ISS):Simulates the behavior of a processor to provide deeper insights
						into code execution.</li>
				</ul>
			</section>

			<section>
				<h2>Performance Profiling</h2>
			</section>

			<section>
				<h3>Performance Profiling</h3>
				<div class="row">
					<div class="column">
						<img src="https://blog.jetbrains.com/wp-content/uploads/2021/08/timeline_viewer.png"
							width="700" />
					</div>
					<div class="column">
						<p>Performance profiling is the process of gathering and analyzing data about the execution of a
							program
							to identify areas where it may be optimized for better efficiency and speed.</p>
						<ul>
							<li>Measuring resource usage (CPU, memory, disk I/O, etc.).</li>
							<li>Identifying bottlenecks and performance hotspots.</li>
							<li>Optimizing code to improve overall program performance.</li>
						</ul>
					</div>
				</div>


			</section>

			<section>
				<h3>Metrics: Call Graph</h3>

				<div class="row">
					<div class="column">
						<img src="https://resources.jetbrains.com/help/img/dotnet/2023.2/tv_plain_list_2.png"
							width="700" />
					</div>
					<div class="column">
						<ul>
							<li>Traces the call journey of functions and methods.</li>
							<li>Helps in understanding the flow of program execution and identifying performance
								bottlenecks.
							</li>
						</ul>
					</div>
				</div>

			</section>

			<section>
				<h3>Metrics: Execution Time</h3>
				<div class="row">
					<div class="column">
						<img src="https://i.stack.imgur.com/g2n7f.png" width="700" />
					</div>
					<div class="column">
						<ul>
							<li>Measuring the time taken by functions and procedures to execute.</li>
							<li>Accounting for nested calls and cumulative execution time.</li>
						</ul>
					</div>
				</div>


			</section>

			<section>
				<h3>Metrics: Call Counts</h3>
				<ul>
					<li>Keeping track of how often procedures are invoked.</li>
					<li>Helpful in identifying frequently called procedures which could be optimized for better
						performance.</li>
				</ul>
			</section>

			<section>
				<h3>Metrics: Thread Block Time</h3>
				<div class="row">
					<div class="column">
						<img src="https://michaelscodingspot.com/wp-content/uploads/2019/11/performance_commonProblems_lockContention_dotTraceTimeline.png" width="700" />
					</div>
					<div class="column">
						<ul>
							<li>Measuring the time threads spend waiting for resource access or at critical sections.
							</li>
							<li>Key for analyzing and improving multi-threaded program performance.</li>
						</ul>
					</div>
				</div>


			</section>

			<section>
				<h3>Metrics: User mode vs Kernel mode Time</h3>
				<ul>
					<li>User Mode: Restricted mode for running application code.</li>
					<li>Kernel Mode: Privileged mode for running system code.</li>
				</ul>
			</section>

			<section>
				<h3>Implementation: Sampling</h3>
				<p>Intermittent processor interruptions for call stack snapshots.</p>
				<p>Example: Sampling might involve pausing the program's execution every 100 milliseconds to capture a
					snapshot of the call stack, which can then be analyzed to understand the code's execution flow and
					performance characteristics.</p>
			</section>

			<section>
				<h3>Implementation: Instrumentation</h3>
				<p>Code augmentation for statistics gathering.</p>
				<p>Example: Instrumentation involves adding code snippets to record function execution times. For
					instance, adding timing code to measure the duration of specific functions or methods during program
					execution.</p>
			</section>

			<section>
				<h3>Implementation: Event Tracing</h3>
				<p>Event tracing involves capturing detailed events and data during program execution for later
					analysis.</p>
				<p>Example: Event tracing can involve logging every network request made by an application, including
					details like request and response times. This data can be invaluable for diagnosing network-related
					performance issues.</p>
			</section>

			<section>
				<h3>Implementation: Performance Counters</h3>
				<p>Performance counters are mechanisms for collecting real-time data on various system and application
					performance metrics.</p>
				<p>Example: Performance counters can track CPU usage, memory usage, and disk I/O in real-time. For
					instance, they can help identify CPU bottlenecks when a program is consuming excessive CPU
					resources.</p>
			</section>

			<section>
				<h2> Memory profiling </h2>
			</section>

			<section>
				<h3>What is Memory Profiling?</h3>
				<p>Memory profiling is the process of monitoring and analyzing a program's memory usage during execution
					to identify memory-related issues and optimize memory management.</p>
				<p>Memory-related issues such as memory leaks, excessive memory consumption, and inefficient memory
					management can lead to application crashes and degraded performance. Memory profiling helps in
					detecting and addressing these issues.</p>
			</section>

			<section>
				<h3>Metrics</h3>

				<div class="row">
					<div class="column">
						<img src="https://www.jetbrains.com/dotmemory/img/screenshots/control.png" width="700" />
					</div>
					<div class="column">
						<p>Memory Footprint: Total memory used by the program.</p>
						<p>Memory footprint measurement in memory profiling refers to the assessment of the overall
							memory
							consumption by the program. It provides insights into how much RAM the program is actively
							using
							during its execution. Monitoring the memory footprint is essential to ensure that the
							program's
							memory usage remains within acceptable limits, preventing excessive memory consumption that
							can lead
							to performance degradation or crashes.</p>
					</div>
				</div>

			</section>

			<section>
				<h3>Metrics</h3>
				<p>Heap and Stack Usage: Understanding what resides in the heap and stack.</p>
				<p>Heap and stack usage analysis in memory profiling involves examining the contents of both the
					program's heap and stack memory regions. The heap stores dynamically allocated objects and data
					structures, while the stack is used for function call frames and local variables. Understanding what
					resides in these memory areas is crucial for optimizing memory management. It helps in identifying
					if objects are unnecessarily held in memory, leading to potential memory leaks or inefficient memory
					utilization.</p>
			</section>
			<section>
				<h3>Metrics</h3>
				<p>Object Dependency: Identifying references preventing garbage collection.</p>
				<p>Object dependency analysis in memory profiling focuses on identifying references and relationships
					between objects in memory. It helps in pinpointing objects that are being held in memory due to
					references, preventing them from being garbage collected when they are no longer needed. Identifying
					and resolving these dependencies is crucial for efficient memory management, as it can prevent
					memory leaks and ensure optimal memory usage.</p>
			</section>

			<section>
				<h3>Metrics</h3>
				<p>Allocation/Deallocation: Analysis of memory allocation and deallocation patterns.</p>
				<p>Analysis of memory allocation and deallocation patterns in memory profiling involves tracking how and
					when memory is allocated and released during program execution. This provides insights into the
					program's memory management behavior. Understanding these patterns helps in optimizing memory usage,
					identifying potential memory fragmentation issues, and ensuring that resources are released properly
					when they are no longer needed, contributing to efficient memory management.</p>
			</section>

			<section>
				<h3>Implementation: Heap Dumps</h3>
				<p>Heap dumps are a memory profiling strategy that involves generating detailed snapshots of the objects
					in the program's heap memory. These snapshots provide a comprehensive view of the objects, their
					sizes, and their relationships. Heap dumps are valuable for diagnosing memory-related issues,
					identifying memory leaks, and understanding memory consumption patterns. Developers can use heap
					dumps to analyze the memory landscape and optimize memory usage effectively.</p>
			</section>

			<section>
				<h3>Implementation: Snapshot Comparison</h3>
				<p>Snapshot comparison is a memory profiling strategy that involves capturing memory snapshots at
					different points in the program's execution and comparing them. This technique helps in identifying
					changes in memory usage over time. By taking snapshots before and after specific program events or
					at regular intervals, developers can track memory allocation and deallocation patterns. Comparing
					snapshots can reveal memory leaks, excessive memory consumption, and areas for memory optimization.
				</p>
			</section>

			<section>
				<h3>Implementation: Object Retention Analysis</h3>
				<p>Object retention analysis is a memory profiling strategy that focuses on identifying objects that are
					being retained in memory longer than necessary. Such retained objects can lead to memory leaks and
					inefficient memory usage. Memory profilers analyze object lifetimes and references to pinpoint
					objects causing retention issues. Developers can then address these problems by releasing references
					appropriately or optimizing object management to improve memory efficiency.</p>
			</section>

			<section>
				<h3>Implementation: Instrumentation</h3>
				<p>Instrumentation is a memory profiling strategy that involves inserting code into the program to
					collect memory-related data. Developers add instrumentation code to monitor key events such as
					object creation, destruction, and memory allocations. This code augmentation provides valuable
					insights into memory usage patterns. Instrumentation can be used to track memory-related metrics and
					detect memory-related issues, aiding in memory profiling and optimization efforts.</p>
			</section>

			<section>
				<h3>Implementation: Memory Allocation Tracking</h3>
				<p>Memory allocation tracking is a memory profiling strategy that monitors memory allocation and
					deallocation events during program execution. By tracking how and when memory is allocated and
					released, developers gain a comprehensive understanding of memory usage patterns. This information
					helps in optimizing memory management, identifying potential memory fragmentation issues, and
					ensuring that resources are released properly when they are no longer needed, contributing to
					efficient memory usage.</p>
			</section>

			<section>
				<h3>Implementation: Garbage Collection Analysis</h3>
				<p>Garbage collection analysis is a memory profiling strategy that focuses on assessing how efficiently
					memory is being reclaimed by the garbage collector. Memory profilers track garbage collection events
					and measure their impact on memory usage. Analyzing garbage collection behavior helps in optimizing
					memory management strategies, identifying long pauses caused by garbage collection, and ensuring
					that memory is reclaimed promptly, contributing to smoother and more efficient program execution.
				</p>
			</section>

			<section>
				<h2>Test Coverage</h2>
			</section>

			<section>
				<h3>What is Test Coverage?</h3>
				<div class="row">
					<div class="column">
						<img src="https://www.jetbrains.com/dotcover/features/img/dotcover-unit-test-coverage.png"
							width="700" />
					</div>
					<div class="column">
						<p>Test coverage is a metric used in software testing to measure the extent to which a set of
							test cases
							exercises or covers a software application's code. It quantifies the percentage of code
							lines,
							functions, statements, or branches that have been executed by the tests. Test coverage helps
							assess
							the thoroughness and effectiveness of the testing process.</p>
					</div>
				</div>
			</section>

			<section>
				<h3>Why is Test Coverage Important?</h3>
				<p>Test coverage is important because it provides insights into the quality and reliability of software.
					It helps answer questions such as:</p>
				<ul>
					<li>Have all critical parts of the code been tested?</li>
					<li>Is there untested code that might contain bugs?</li>
					<li>Are the test cases comprehensive enough to catch potential issues?</li>
				</ul>
				<p>High test coverage increases confidence in the software's correctness and helps in identifying areas
					that need additional testing or improvement.</p>
			</section>

			<section>
				<h3>Test Coverage Metrics</h3>
				<p>There are several types of test coverage metrics, including:</p>
				<ul>
					<li>Line Coverage: Measures the percentage of code lines executed by tests.</li>
					<li>Function Coverage: Measures the percentage of functions or methods called by tests.</li>
					<li>Statement Coverage: Measures the percentage of individual statements executed by tests.</li>
					<li>Branch Coverage: Measures the percentage of code branches taken by tests, assessing decisions
						and conditional logic.</li>
				</ul>
			</section>

			<section>
				<h3>Interpreting Test Coverage Results</h3>
				<p>Interpreting test coverage results involves analyzing the coverage percentage and understanding its
					implications:</p>
				<ul>
					<li>High Coverage: A high coverage percentage indicates that a significant portion of the code has
						been tested. It suggests good test comprehensiveness.</li>
					<li>Low Coverage: A low coverage percentage indicates that a substantial part of the code remains
						untested. It may signify the presence of unverified code paths and potential issues.</li>
					<li>Targeted Improvements: Identifying areas with low coverage allows teams to focus on writing
						additional tests for critical code paths.</li>
				</ul>
				<p>Test coverage results guide testing efforts and help prioritize testing resources.</p>
			</section>


			<section>
				<h3>Implementation: Instrumentation</h3>
				<p>The first step in dynamic analysis for test coverage measurement is instrumentation. Instrumentation
					involves adding code to the program under test to record information about code execution. This
					added code, often referred to as "probes" or "coverage counters," tracks which parts of the code are
					executed during test runs. These probes are strategically placed within the code to collect coverage
					data.</p>
			</section>

			<section>
				<h3>Implementation: Test Execution</h3>
				<p>After instrumenting the code, the next step is to execute the test suite. During test execution, the
					probes or coverage counters record data about which code paths are taken. As the tests run, the
					coverage data accumulates, providing information about the extent to which the code is exercised by
					the tests.</p>
			</section>

			<section>
				<h3>Implementation: Data Collection</h3>
				<p>Once the tests are executed, the data collected by the coverage counters is typically stored in a
					data structure or file. This data includes details about which lines of code, functions, or branches
					were executed during the test run. The collected data serves as the basis for calculating test
					coverage metrics.</p>
			</section>

			<section>
				<h3>Implementation: Coverage Analysis</h3>
				<p>After data collection, coverage analysis is performed to determine the extent of code coverage
					achieved by the tests. This analysis involves calculating coverage metrics such as line coverage,
					function coverage, statement coverage, or branch coverage. These metrics indicate the percentage of
					code exercised by the tests and provide insights into test comprehensiveness.</p>
			</section>

			<section>
				<h3>Implementation: Reporting and Visualization</h3>
				<p>Dynamic analysis tools often provide reporting and visualization capabilities to present test
					coverage results in an understandable format. Reports may include coverage percentages, detailed
					coverage maps, and visual representations of covered and uncovered code paths. These reports help
					teams assess test coverage and identify areas that require additional testing.</p>
			</section>

			<section>
				<h2>Conclusion</h2>
			</section>

			<section>
				<h3>What to read?</h3>
				<ol>
					<li>"Dynamic Analysis: Theoretical Developments and Applications" by Felienne Hermans</li>
					<li>"Dynamic Program Analysis and Software Exploitation" by Chris Eagle</li>
					<li>"Dynamic Analysis and Design of Offshore Structures" by Srinivasan Chandrasekaran and S. Rajan
					</li>
					<li>"Advanced Dynamic Analysis Techniques for Software Testing and Debugging" by Pei Hsia, Ali Mili,
						and Khaled El-Fakih</li>
				</ol>
			</section>

			<section>
				<h3>Next: Debuggers</h3>
				<p>In the upcoming section, we will delve into the world of debuggers. Debuggers are essential tools for
					code analysis and correction. We will explore their roles, features, and implementation insights.
					Let's embark on this journey to understand how debuggers contribute to the development process.</p>
			</section>

			<section>
				<h3>Questions & Answers</h3>
				<p>Thank you for your attention!</p>
				<p>I'm now open to any questions you might have.</p>
			</section>

			<script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.5.0/reveal.min.js"></script>
			<script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.5.0/plugin/notes/notes.min.js"></script>
			<script
				src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.5.0/plugin/highlight/highlight.min.js"></script>
			<script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/4.5.0/plugin/math/math.min.js"></script>
			<script
				src="https://cdn.jsdelivr.net/npm/reveal.js-mermaid-plugin@2.0.0/plugin/mermaid/mermaid.js"></script>
			<script>
				Reveal.initialize({
					hash: true,
					width: 1920,
					height: 1080,
					center: true,
					margin: 0,
					mermaid: {},
					plugins: [RevealHighlight, RevealNotes, RevealMath.KaTeX, RevealMermaid]
				});
			</script>
</body>

</html>